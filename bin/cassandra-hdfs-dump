#!/usr/bin/env ruby

require 'rubygems'
require 'wukong'
require 'configliere' ; Configliere.use(:commandline, :env_var, :define)

Settings.define :ks,               :default => "Keyspace1",                     :description => "Cassandra Keyspace to write data to"
Settings.define :cf,               :default => "Standard1",                     :description => "Cassandra Column Family to write to"
Settings.define :col_names,        :default => "timeseries_json",               :description => "Comma separated list of column names to retrieve"
Settings.define :cassandra_home,   :default => "/usr/local/share/cassandra",    :description => "Path to cassandra installation. Reads from CASSANDRA_HOME", :env_var => "CASSANDRA_HOME"
Settings.define :hadoop_home,      :default => "/usr/lib/hadoop",               :description => "Path to hadoop installation", :env_var => "HADOOP_HOME"
Settings.define :batch_size,       :default => "1024",                          :description => "Number of rows to pull from Cassandra per range request. Too big and you'll run out of heap space or get timeouts. Too small and overhead of each request will kill perf."
Settings.define :host,             :default => "192.168.1.119",                 :description => "Initial cassandra host to connect to"
Settings.define :port,             :default => "9160",                          :description => "Port on host to send thrift rpc to"
Settings.define :rm,               :default => false,                           :description => "Remove output file if it already exists?"

Settings.define :vals,             :default => false,                           :description => "Fetch all column values matched by col_names"
Settings.define :names,            :default => false,                           :description => "Fetch all column names"
Settings.resolve!

class CassandraHdfsDump
  attr_accessor :options

  def initialize
    @options = Settings.dup
  end

  def execute
    output = options.rest.first
    remove_output(output) if options.rm
    hadoop_cmd = [
      "HADOOP_CLASSPATH=#{hadoop_classpath}",
      "#{options.hadoop_home}/bin/hadoop jar #{run_jar}",
      mainclass,
      "-Dcassandra.thrift_port=#{options.port}",
      "-Dcassandra.initial_host=#{options.host}",
      "-Dcassandra.keyspace=#{options.ks}",
      "-Dcassandra.column_family=#{options.cf}",
      "-Dcassandra.batch_size=#{options.batch_size}",
      "-Dcassandra.column_names=#{options.col_names}",
      "-libjars #{libjars}",
      "#{output}",
    ].flatten.compact.join(" \t\\\n  ")
    system %Q{ echo #{hadoop_cmd} }
    system %Q{ #{hadoop_cmd} }
  end

  def hadoop_classpath
    hdp_cp = []
    Dir[
      "#{options.cassandra_home}/lib/*cassandra*.jar",
      "#{options.cassandra_home}/lib/*thrift*.jar"
    ].each{|jar| hdp_cp << jar}
    hdp_cp.join(':')
  end

  def run_jar
    File.dirname(File.expand_path(__FILE__))+'/../build/cassandra_hdfs_dump.jar'
  end

  def libjars
    libjars = []
    Dir[
      "#{options.cassandra_home}/lib/*.jar"
    ].each{|jar| libjars << jar}
    libjars.join(',')
  end

  def mainclass
    return "CassandraTableDump" if options.vals
    return "CassandraNamesDump" if options.names
  end

  def remove_output output
    system %Q{ hdp-rm -r #{output} }
  end

end

runner = CassandraHdfsDump.new
runner.execute
